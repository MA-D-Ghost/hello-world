{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHo ten: Ton Thien Minh Anh\\nMSSV: 18110049\\nBai thuc hanh Lab06 - Bai 1\\n\\n1. Defining the functions correspond with the feature selection or dimensionality reduction\\ntechnologies.\\n2. Giving examples to demonstrate your function works\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ho ten: Ton Thien Minh Anh\n",
    "MSSV: 18110049\n",
    "Bai thuc hanh Lab06 - Bai 1\n",
    "\n",
    "1. Defining the functions correspond with the feature selection or dimensionality reduction\n",
    "technologies.\n",
    "2. Giving examples to demonstrate your function works\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (<ipython-input-2-cb288f5dcd79>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-cb288f5dcd79>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    def Constant_Features(threshold=0, x_train, x_test):\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "# ============== DEFINING THE FUNCTIONS ==============\n",
    "def Constant_Features(threshold=0, x_train, x_test):\n",
    "  \"\"\"\n",
    "  Removing Constant Features using Variance Threshold\n",
    "  Input: threshold parameter to identify the variable as constant\n",
    "         train data (pd.Dataframe) \n",
    "         test data (pd.Dataframe)\n",
    "  Output: train data, test data after applying filter methods\n",
    "  \"\"\"\n",
    "  # import and create the VarianceThreshold object.\n",
    "  from sklearn.feature_selection import VarianceThreshold\n",
    "  vs_constant = VarianceThreshold(threshold)\n",
    "\n",
    "  # select the numerical columns only.\n",
    "  numerical_x_train = x_train[x_train.select_dtypes([np.number]).columns]\n",
    "\n",
    "  # fit the object to our data.\n",
    "  vs_constant.fit(numerical_x_train)\n",
    "\n",
    "  # get the constant colum names.\n",
    "  constant_columns = [column for column in numerical_x_train.columns\n",
    "                      if column not in numerical_x_train.columns[vs_constant.get_support()]]\n",
    "\n",
    "  # detect constant categorical variables.\n",
    "  constant_cat_columns = [column for column in x_train.columns \n",
    "                          if (x_train[column].dtype == \"O\" and len(x_train[column].unique())  == 1 )]\n",
    "\n",
    "  # concatenating the two lists.\n",
    "  all_constant_columns = constant_cat_columns + constant_columns\n",
    "\n",
    "  # drop the constant columns\n",
    "  x_train = x_train.drop(labels=all_constant_columns, axis=1, inplace=True)\n",
    "  x_test = x_test.drop(labels=all_constant_columns, axis=1, inplace=True)\n",
    "  return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (<ipython-input-3-4bdf833538dc>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-4bdf833538dc>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def Quasi_Constant_Features(threshold=0.98, x_train, x_test):\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "def Quasi_Constant_Features(threshold=0.98, x_train, x_test):\n",
    "    \"\"\"\n",
    "  Removing Quasi Constant Features using Variance Threshold\n",
    "  Input: threshold parameter to identify the variable as quasi constant\n",
    "         train data (pd.Dataframe) \n",
    "         test data (pd.Dataframe)\n",
    "  Output: train data, test data after applying filter methods\n",
    "  \"\"\"\n",
    "    # create empty list\n",
    "    quasi_constant_feature = []\n",
    "\n",
    "    # loop over all the columns\n",
    "    for feature in x_train.columns:\n",
    "\n",
    "        # calculate the ratio.\n",
    "        predominant = (x_train[feature].value_counts() / np.float(len(x_train))).sort_values(ascending=False).values[0]\n",
    "    \n",
    "        # append the column name if it is bigger than the threshold\n",
    "        if predominant >= threshold:\n",
    "            quasi_constant_feature.append(feature)   \n",
    "        \n",
    "    print(quasi_constant_feature)\n",
    "\n",
    "    # drop the quasi constant columns\n",
    "    x_train = x_train.drop(labels=quasi_constant_feature, axis=1, inplace=True)\n",
    "    x_test = x_test.drop(labels=quasi_constant_feature, axis=1, inplace=True)\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_Duplicated_Features(x_train,x_test):\n",
    "    # transpose the feature matrice\n",
    "    train_features_T = x_train.T\n",
    "\n",
    "    # print the number of duplicated features\n",
    "    print(train_features_T.duplicated().sum())\n",
    "\n",
    "    # select the duplicated features columns names\n",
    "    duplicated_columns = train_features_T[train_features_T.duplicated()].index.values\n",
    "\n",
    "    # drop those columns\n",
    "    x_train = x_train.drop(labels=duplicated_columns, axis=1, inplace=True)\n",
    "    x_test = x_test.drop(labels=duplicated_columns, axis=1, inplace=True)\n",
    "    return x_train,x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Correlation_Filter(x_train,x_test):\n",
    "    # creating set to hold the correlated features\n",
    "    corr_features = set()\n",
    "\n",
    "    # create the correlation matrix (default to pearson)\n",
    "    corr_matrix = x_train.corr()\n",
    "\n",
    "    # optional: display a heatmap of the correlation matrix\n",
    "    plt.figure(figsize=(11,11))\n",
    "    sns.heatmap(corr_matrix)\n",
    "\n",
    "    for i in range(len(corr_matrix .columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > 0.8:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                corr_features.add(colname)\n",
    "            \n",
    "    x_train = x_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    x_test = x_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    return x_train,x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
